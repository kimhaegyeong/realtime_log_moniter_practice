services:
  # Zookeeper - Kafka의 메타데이터 관리
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      TZ: Asia/Seoul
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - log-network

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      TZ: Asia/Seoul
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # 외부 접속용 (localhost)
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # 성능 설정
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # 로그 설정
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - log-network
    healthcheck:
      test: [ "CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka UI - 카프카 모니터링 및 관리
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      TZ: Asia/Seoul
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - log-network

  # MongoDB
  mongodb:
    image: mongo:7.0
    container_name: mongodb
    ports:
      - "27017:27017"
    environment:
      TZ: Asia/Seoul
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE}
    volumes:
      - mongodb-data:/data/db
      - ./mongo-init:/docker-entrypoint-initdb.d
    networks:
      - log-network
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # MongoDB Express - MongoDB GUI
  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    depends_on:
      - mongodb
    ports:
      - "8081:8081"
    environment:
      TZ: Asia/Seoul
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_ROOT_USERNAME}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_ROOT_PASSWORD}
      ME_CONFIG_MONGODB_URL: mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@mongodb:27017/
      ME_CONFIG_BASICAUTH_USERNAME: ${MONGO_EXPRESS_USERNAME}
      ME_CONFIG_BASICAUTH_PASSWORD: ${MONGO_EXPRESS_PASSWORD}
    networks:
      - log-network
    # Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  # Log Producer API Service (FastAPI)
  log-producer-api:
    build:
      context: ./services/log-producer
      dockerfile: Dockerfile
    container_name: log-producer-api
    depends_on:
      - kafka
      - mongodb
    ports:
      - "8000:8000"
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      SERVICE_NAME: log-producer-api
      LOG_LEVEL: INFO
    networks:
      - log-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    command: [ "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000" ]

  # Log Aggregator Service
  log-aggregator:
    build:
      context: ./services/log-aggregator
      dockerfile: Dockerfile
    container_name: log-aggregator
    depends_on:
      - mongodb
    ports:
      - "8001:8001"
    environment:
      MONGODB_URI: mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@mongodb:27017/
      MONGODB_DATABASE: ${MONGO_DATABASE}
    networks:
      - log-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8001/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Log Consumer Service (3 replicas for parallel processing)
  log-consumer-1:
    build:
      context: ./services/log-consumer
      dockerfile: Dockerfile
    container_name: log-consumer-1
    depends_on:
      - kafka
      - mongodb
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      KAFKA_GROUP_ID: log-consumer-group
      MONGODB_URI: mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@mongodb:27017/
      MONGODB_DATABASE: ${MONGO_DATABASE}
      BATCH_SIZE: 500
    networks:
      - log-network
    command: [ "python", "-m", "app.main" ]
    restart: unless-stopped

  log-consumer-2:
    build:
      context: ./services/log-consumer
      dockerfile: Dockerfile
    container_name: log-consumer-2
    depends_on:
      - kafka
      - mongodb
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      KAFKA_GROUP_ID: log-consumer-group
      MONGODB_URI: mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@mongodb:27017/
      MONGODB_DATABASE: ${MONGO_DATABASE}
      BATCH_SIZE: 500
    networks:
      - log-network
    command: [ "python", "-m", "app.main" ]
    restart: unless-stopped

  log-consumer-3:
    build:
      context: ./services/log-consumer
      dockerfile: Dockerfile
    container_name: log-consumer-3
    depends_on:
      - kafka
      - mongodb
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      KAFKA_GROUP_ID: log-consumer-group
      MONGODB_URI: mongodb://${MONGO_ROOT_USERNAME}:${MONGO_ROOT_PASSWORD}@mongodb:27017/
      MONGODB_DATABASE: ${MONGO_DATABASE}
      BATCH_SIZE: 500
    networks:
      - log-network
    command: [ "python", "-m", "app.main" ]
    restart: unless-stopped

  # Auto Producer - API Service
  producer-api-service:
    build:
      context: ./services/log-producer
      dockerfile: Dockerfile
    container_name: producer-api-service
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      SERVICE_NAME: api-service
      LOGS_PER_SECOND: 50
    networks:
      - log-network
    restart: unless-stopped
    command: [ "python", "-m", "app.main_auto" ]

  # Auto Producer - Auth Service
  producer-auth-service:
    build:
      context: ./services/log-producer
      dockerfile: Dockerfile
    container_name: producer-auth-service
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      SERVICE_NAME: auth-service
      LOGS_PER_SECOND: 30
    networks:
      - log-network
    restart: unless-stopped
    command: [ "python", "-m", "app.main_auto" ]

  # Auto Producer - Payment Service
  producer-payment-service:
    build:
      context: ./services/log-producer
      dockerfile: Dockerfile
    container_name: producer-payment-service
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: logs
      SERVICE_NAME: payment-service
      LOGS_PER_SECOND: 20
    networks:
      - log-network
    restart: unless-stopped
    command: [ "python", "-m", "app.main_auto" ]

  # Grafana - 대시보드
  grafana:
    image: grafana/grafana:12.3.0
    container_name: grafana
    depends_on:
      - mongodb
    ports:
      - "3000:3000"
    environment:
      - GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS=haohanyang-mongodb-datasource
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      # Enterprise MongoDB 플러그인 사용
      #- GF_INSTALL_PLUGINS=grafana-mongodb-datasource
      - GF_AUTH_ANONYMOUS_ENABLED=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      # 플러그인 설치를 위한 WSL 경로 바인드
      - ./monitoring/grafana/plugins:/var/lib/grafana/plugins
    networks:
      - log-network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3

# 볼륨 정의 (데이터 영속성)
volumes:
  zookeeper-data:
    driver: local
  zookeeper-logs:
    driver: local
  kafka-data:
    driver: local
  mongodb-data:
    driver: local
  grafana-data:
    driver: local
  prometheus_data:
    driver: local

# 네트워크 정의
networks:
  log-network:
    name: log-monitoring-network # 명시적 이름 지정
    driver: bridge
