apiVersion: v1
kind: ConfigMap
metadata:
  name: log-monitoring-config
  namespace: log-monitoring
data:
  KAFKA_BOOTSTRAP_SERVERS: "kafka.log-monitoring.svc.cluster.local:9092"
  KAFKA_TOPIC: "logs"
  KAFKA_PARTITIONS: "10"
  MONGODB_DATABASE: "logs"
  BATCH_SIZE: "500"
  LOGS_PER_SECOND_API: "50"
  LOGS_PER_SECOND_AUTH: "30"
  LOGS_PER_SECOND_PAYMENT: "20"
  MONGODB_URI: "mongodb://admin:admin123@mongodb:27017/"
  
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-provisioning
  namespace: log-monitoring
  labels:
    app: grafana
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus-server.monitoring.svc.cluster.local:9090
        access: proxy
        isDefault: true
      - name: MongoDB
        type: haohanyang-mongodb-datasource
        uid: mongodb
        url: mongodb://mongodb-0.mongodb.log-monitoring.svc.cluster.local:27017
        jsonData:
          database: "logs"
        secureJsonData:
          username: "${MONGO_ROOT_USERNAME}"
          password: "${MONGO_ROOT_PASSWORD}"
  dashboards.yaml: |
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /etc/grafana/provisioning/dashboards

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'log-aggregator'
        static_configs:
          - targets: ['log-aggregator:8001']
        scrape_interval: 10s
        
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health {
           lameduck 5s
        }
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }