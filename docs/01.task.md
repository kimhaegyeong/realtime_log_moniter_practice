# 실시간 로그 수집 및 모니터링 시스템 - Task 계획

## 📋 프로젝트 개요
**목표**: Kafka + MongoDB + Kubernetes 기반의 확장 가능한 로그 수집 및 모니터링 시스템 구축

---

## 🎯 Phase 1: 환경 설정 및 기본 구조 (Week 1)

### TASK-1: 프로젝트 초기 설정 (2-3시간)
- [X] GitHub 레포지토리 생성
- [X] 프로젝트 디렉토리 구조 설계
  ```
  log-monitoring-system/
  ├── docker-compose.yml
  ├── k8s/
  ├── services/
  │   ├── log-producer/
  │   ├── log-consumer/
  │   └── log-aggregator/
  ├── monitoring/
  └── README.md
  ```
- [X] .gitignore 설정
- [X] 기술 스택 및 버전 명시 문서 작성

**완료 기준**: Git 레포지토리가 생성되고 기본 디렉토리 구조가 준비됨

---

### TASK-2: Docker Compose로 로컬 개발 환경 구축 (3-4시간)
- [X] Kafka 컨테이너 설정 (Zookeeper 포함 또는 KRaft 모드)
- [X] MongoDB 컨테이너 설정
- [X] Kafka UI 추가 (akhq 또는 kafka-ui)
- [X] MongoDB Express 추가 (선택사항)
- [X] docker-compose.yml 작성 및 테스트

**완료 기준**: `docker-compose up`으로 Kafka와 MongoDB가 정상 실행됨

**테스트 방법**:
```bash
# Kafka 토픽 생성 테스트
docker exec -it kafka kafka-topics --create --topic test --bootstrap-server localhost:9092

# MongoDB 연결 테스트
docker exec -it mongodb mongosh
```

---

### TASK-3: Log Producer 서비스 개발 (4-5시간)
- [X] 프로그래밍 언어 선택 (Go/Python/Node.js)
  - Python 선택
- [X] Kafka Producer 라이브러리 설정
- [X] 로그 생성 로직 구현
  - HTTP API 엔드포인트 (예: `/api/logs`)
  - 랜덤 로그 생성기 (시뮬레이션용)
- [X] 로그 포맷 정의 (JSON)
  ```json
  {
    "timestamp": "2024-01-15T10:30:00Z",
    "level": "INFO",
    "service": "api-service",
    "message": "User login successful",
    "metadata": {
      "user_id": "12345",
      "ip": "192.168.1.1"
    }
  }
  ```
- [X] Kafka 토픽으로 전송 구현
- [X] 에러 핸들링 및 재시도 로직

**완료 기준**: Producer가 Kafka로 로그를 정상 전송하고, Kafka UI에서 확인 가능

---

### TASK-4: Log Consumer 서비스 개발 (4-5시간)
- [X] Kafka Consumer 라이브러리 설정
- [X] MongoDB 연결 설정
- [X] Consumer Group 설정
- [X] 로그 수신 및 파싱
- [X] MongoDB 저장 로직 구현
  - Collection 설계: `logs`, `logs_hourly_stats`
  - 인덱스 설정: `timestamp`, `service`, `level`
- [X] 배치 처리 구현 (성능 최적화)
- [X] 에러 핸들링 (Dead Letter Queue 고려)

**완료 기준**: Consumer가 Kafka에서 메시지를 읽어 MongoDB에 저장

**테스트 방법**:
```javascript
// MongoDB에서 확인
db.logs.find().limit(10)
db.logs.countDocuments()
```

---

### TASK-5: 여러 Producer 인스턴스 시뮬레이션 (2-3시간)
- [x] 3개의 서로 다른 서비스 시뮬레이션
  - `api-service`: API 요청 로그
  - `auth-service`: 인증 관련 로그
  - `payment-service`: 결제 관련 로그
- [x] 각각 다른 로그 패턴 생성
- [x] 부하 테스트 스크립트 작성 (초당 100-1000개 로그 생성)

**완료 기준**: 3개의 Producer가 동시에 로그를 생성하고 정상 처리됨

---

## 🚀 Phase 2: 집계 및 모니터링 (Week 2)

### TASK-6: Log Aggregator 서비스 개발 (5-6시간)
- [X] MongoDB Aggregation Pipeline 설계
- [X] 시간대별 통계 집계 (1분, 5분, 1시간 단위)
  - 로그 레벨별 카운트
  - 서비스별 카운트
  - 에러율 계산
- [X] 집계 결과를 별도 Collection에 저장
- [X] 스케줄러 구현 (cron 또는 주기적 실행)
- [X] 집계 API 엔드포인트 개발
  ```
  GET /api/stats/hourly?service=api-service&start=...&end=...
  GET /api/stats/error-rate?service=all
  ```

**완료 기준**: 집계 서비스가 주기적으로 통계를 생성하고 API로 조회 가능

**MongoDB Aggregation 예시**:
```javascript
db.logs.aggregate([
  {
    $match: {
      timestamp: { $gte: ISODate("2024-01-15T00:00:00Z") }
    }
  },
  {
    $group: {
      _id: {
        service: "$service",
        level: "$level",
        hour: { $dateToString: { format: "%Y-%m-%d-%H", date: "$timestamp" } }
      },
      count: { $sum: 1 }
    }
  }
])
```

---

### TASK-7: Grafana 대시보드 구축 (4-5시간)
- [X] Grafana 컨테이너 추가 (docker-compose)
- [X] MongoDB 데이터소스 플러그인 설치
- [X] 대시보드 패널 구성
  - 실시간 로그 유입량 그래프
  - 서비스별 로그 분포 (Pie Chart)
  - 에러 로그 타임라인
  - 최근 로그 테이블
- [X] Alert 규칙 설정 (에러율이 임계값 초과 시)
- [ ] 대시보드 JSON 파일 저장 (버전 관리)

**완료 기준**: Grafana에서 실시간 로그 통계를 시각화 가능

---

### TASK-8: 성능 최적화 및 테스트 (3-4시간)
- [ ] MongoDB 인덱스 최적화
  ```javascript
  db.logs.createIndex({ timestamp: -1, service: 1 })
  db.logs.createIndex({ level: 1, timestamp: -1 })
  ```
- [ ] Kafka 파티션 설정 최적화
- [ ] Consumer 병렬 처리 확인
- [ ] 부하 테스트
  - 목표: 10,000 logs/second 처리
  - 도구: Apache JMeter, k6, 또는 자체 스크립트
- [ ] 메모리 및 CPU 사용량 모니터링
- [ ] 병목 지점 파악 및 개선

**완료 기준**: 초당 10,000개 로그를 안정적으로 처리

---

## ☸️ Phase 3: Kubernetes 배포 (Week 3)

### TASK-9: Kubernetes 매니페스트 작성 (5-6시간)
- [ ] Minikube 또는 Kind 클러스터 설정
- [ ] Namespace 생성: `log-monitoring`
- [ ] ConfigMap 작성 (각 서비스 설정)
- [ ] Secret 작성 (MongoDB 인증 정보)
- [ ] Kafka Deployment & Service
  - StatefulSet 사용 (데이터 영속성)
  - Headless Service 설정
- [ ] MongoDB Deployment & Service
  - StatefulSet + PersistentVolumeClaim
- [ ] Producer Deployment
  - Replicas: 3
- [ ] Consumer Deployment
  - Replicas: 3
- [ ] Aggregator Deployment
- [ ] Grafana Deployment & Service (LoadBalancer 또는 NodePort)

**완료 기준**: 모든 서비스가 K8s 클러스터에 배포되고 정상 작동

**테스트 방법**:
```bash
kubectl get pods -n log-monitoring
kubectl logs -f <producer-pod> -n log-monitoring
kubectl port-forward svc/grafana 3000:3000 -n log-monitoring
```

---

### TASK-10: Horizontal Pod Autoscaler 설정 (2-3시간)
- [ ] Metrics Server 설치
- [ ] HPA 리소스 정의
  ```yaml
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: log-consumer-hpa
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: log-consumer
    minReplicas: 2
    maxReplicas: 10
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
  ```
- [ ] 부하 테스트로 Auto-scaling 확인
- [ ] 스케일링 동작 모니터링

**완료 기준**: CPU 사용률에 따라 Pod가 자동으로 증가/감소

---

### TASK-11: Health Check 및 Rolling Update (2-3시간)
- [ ] Liveness Probe 추가 (각 서비스)
- [ ] Readiness Probe 추가
- [ ] Rolling Update 전략 설정
  ```yaml
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  ```
- [ ] 무중단 배포 테스트
- [ ] Rollback 시나리오 테스트

**완료 기준**: 서비스 중단 없이 새 버전 배포 가능

---

## 📚 Phase 4: 문서화 및 마무리 (Week 3)

### TASK-12: 아키텍처 다이어그램 작성 (2시간)
- [ ] 시스템 전체 아키텍처 다이어그램
- [ ] 데이터 플로우 다이어그램
- [ ] Kubernetes 리소스 구조도
- [ ] 도구: draw.io, Lucidchart, 또는 PlantUML

**완료 기준**: 누구나 이해할 수 있는 시각화 자료 완성

---

### TASK-13: README 작성 (3-4시간)
- [ ] 프로젝트 소개
- [ ] 기술 스택 및 선택 이유
- [ ] 아키텍처 설명
- [ ] 로컬 실행 방법
  ```bash
  # Docker Compose
  docker-compose up -d
  
  # Kubernetes
  kubectl apply -f k8s/
  ```
- [ ] API 문서
- [ ] 성능 테스트 결과
- [ ] 트러블슈팅 가이드
- [ ] 향후 개선 사항

**완료 기준**: 다른 개발자가 README만 보고 프로젝트 실행 가능

---

### TASK-14: 기술 블로그 포스팅 (3-4시간)
- [ ] 주제 선정
  - "Kafka와 MongoDB로 확장 가능한 로그 시스템 구축하기"
  - "Kubernetes HPA를 활용한 로그 처리 성능 최적화"
- [ ] 기술적 도전 과제 및 해결 과정
- [ ] 성능 최적화 사례
- [ ] 배운 점 정리

**완료 기준**: Medium, velog, 또는 개인 블로그에 포스팅

---

### TASK-15: 이력서 업데이트 (1시간)
- [ ] 프로젝트 섹션 작성
  ```
  [토이 프로젝트] 실시간 로그 수집 및 모니터링 시스템
  - Kafka를 활용한 이벤트 기반 로그 수집 파이프라인 구축 (처리량: 10K logs/sec)
  - MongoDB Aggregation Pipeline을 통한 실시간 로그 분석 및 통계 생성
  - Kubernetes HPA를 활용한 Auto-scaling 구현 (부하에 따라 2-10개 Pod 자동 조정)
  - Grafana 대시보드를 통한 실시간 모니터링 시스템 구축
  - 기술 스택: Kafka, MongoDB, Kubernetes, Grafana, Docker, Go/Python
  - GitHub: [링크]
  ```
- [ ] 기술 스택 섹션에 Kafka, Kubernetes, MongoDB 추가

---

## 🎁 선택적 개선 사항 (시간 여유 시)

### TASK-16: 추가 기능 구현 (선택)
- [ ] Elasticsearch 연동 (전문 검색)
- [ ] Redis 캐싱 레이어 추가
- [ ] Prometheus + AlertManager 통합
- [ ] 로그 retention 정책 구현 (오래된 로그 자동 삭제)
- [ ] API 인증 추가 (JWT)
- [ ] CI/CD 파이프라인 구축 (GitHub Actions)
- [ ] Helm Chart 작성

---

## 📊 진행 상황 체크리스트

### Week 1 목표
- [x] 로컬 개발 환경 구축
- [x] Producer, Consumer 서비스 개발
- [x] 기본 로그 수집 파이프라인 완성

### Week 2 목표
- [x] 집계 서비스 및 API 개발
- [x] Grafana 대시보드 구축
- [x] 성능 테스트 및 최적화

### Week 3 목표
- [x] Kubernetes 배포
- [x] Auto-scaling 설정
- [x] 문서화 완료

---

## 🚨 트러블슈팅 예상 포인트

1. **Kafka Consumer Lag 발생**
   - Consumer 수 증가 또는 배치 사이즈 조정

2. **MongoDB Write 성능 이슈**
   - 배치 Insert 사용, 인덱스 최적화

3. **Kubernetes 네트워크 문제**
   - Service 타입 확인, DNS 설정 검증

4. **Grafana 데이터소스 연결 실패**
   - MongoDB 인증 정보 확인, 네트워크 정책 점검

---

## 🎯 성공 지표

- **기능**: 3개 서비스에서 로그를 수집하여 MongoDB에 저장
- **성능**: 초당 10,000개 로그 처리
- **안정성**: 24시간 연속 운영 시 데이터 손실 없음
- **확장성**: HPA로 부하에 따라 자동 스케일링
- **모니터링**: Grafana에서 실시간 시각화

---

**프로젝트 완료 후 얻게 될 역량**:
- ✅ Kafka 기반 이벤트 스트리밍 아키텍처 구현 능력
- ✅ MongoDB 스키마 설계 및 Aggregation 활용 능력
- ✅ Kubernetes를 활용한 컨테이너 오케스트레이션 경험
- ✅ 대용량 데이터 처리 및 성능 최적화 경험
- ✅ 분산 시스템 운영 및 모니터링 능력