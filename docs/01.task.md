# 실시간 로그 수집 및 모니터링 시스템 - Task 계획

## 📋 프로젝트 개요
**목표**: Kafka + MongoDB + Kubernetes 기반의 확장 가능한 로그 수집 및 모니터링 시스템 구축

---

## 🎯 Phase 1: 환경 설정 및 기본 구조 (Week 1)

### TASK-1: 프로젝트 초기 설정 (2-3시간)
- [X] GitHub 레포지토리 생성
- [X] 프로젝트 디렉토리 구조 설계
  ```
  log-monitoring-system/
  ├── docker-compose.yml
  ├── k8s/
  ├── services/
  │   ├── log-producer/
  │   ├── log-consumer/
  │   └── log-aggregator/
  ├── monitoring/
  └── README.md
  ```
- [X] .gitignore 설정
- [X] 기술 스택 및 버전 명시 문서 작성

**완료 기준**: Git 레포지토리가 생성되고 기본 디렉토리 구조가 준비됨

---

### TASK-2: Docker Compose로 로컬 개발 환경 구축 (3-4시간)
- [X] Kafka 컨테이너 설정 (Zookeeper 포함 또는 KRaft 모드)
- [X] MongoDB 컨테이너 설정
- [X] Kafka UI 추가 (akhq 또는 kafka-ui)
- [X] MongoDB Express 추가 (선택사항)
- [X] docker-compose.yml 작성 및 테스트

**완료 기준**: `docker-compose up`으로 Kafka와 MongoDB가 정상 실행됨

**테스트 방법**:
```bash
# Kafka 토픽 생성 테스트
docker exec -it kafka kafka-topics --create --topic test --bootstrap-server localhost:9092

# MongoDB 연결 테스트
docker exec -it mongodb mongosh
```

---

### TASK-3: Log Producer 서비스 개발 (4-5시간)
- [X] 프로그래밍 언어 선택 (Go/Python/Node.js)
  - Python 선택
- [X] Kafka Producer 라이브러리 설정
- [X] 로그 생성 로직 구현
  - HTTP API 엔드포인트 (예: `/api/logs`)
  - 랜덤 로그 생성기 (시뮬레이션용)
- [X] 로그 포맷 정의 (JSON)
  ```json
  {
    "timestamp": "2024-01-15T10:30:00Z",
    "level": "INFO",
    "service": "api-service",
    "message": "User login successful",
    "metadata": {
      "user_id": "12345",
      "ip": "192.168.1.1"
    }
  }
  ```
- [X] Kafka 토픽으로 전송 구현
- [X] 에러 핸들링 및 재시도 로직

**완료 기준**: Producer가 Kafka로 로그를 정상 전송하고, Kafka UI에서 확인 가능

---

### TASK-4: Log Consumer 서비스 개발 (4-5시간)
- [X] Kafka Consumer 라이브러리 설정
- [X] MongoDB 연결 설정
- [X] Consumer Group 설정
- [X] 로그 수신 및 파싱
- [X] MongoDB 저장 로직 구현
  - Collection 설계: `logs`, `logs_hourly_stats`
  - 인덱스 설정: `timestamp`, `service`, `level`
- [X] 배치 처리 구현 (성능 최적화)
- [X] 에러 핸들링 (Dead Letter Queue 고려)

**완료 기준**: Consumer가 Kafka에서 메시지를 읽어 MongoDB에 저장

**테스트 방법**:
```javascript
// MongoDB에서 확인
db.logs.find().limit(10)
db.logs.countDocuments()
```

---

### TASK-5: 여러 Producer 인스턴스 시뮬레이션 (2-3시간)
- [x] 3개의 서로 다른 서비스 시뮬레이션
  - `api-service`: API 요청 로그
  - `auth-service`: 인증 관련 로그
  - `payment-service`: 결제 관련 로그
- [x] 각각 다른 로그 패턴 생성
- [x] 부하 테스트 스크립트 작성 (초당 100-1000개 로그 생성)

**완료 기준**: 3개의 Producer가 동시에 로그를 생성하고 정상 처리됨

---

## 🚀 Phase 2: 집계 및 모니터링 (Week 2)

### TASK-6: Log Aggregator 서비스 개발 (5-6시간)
- [X] MongoDB Aggregation Pipeline 설계
- [X] 시간대별 통계 집계 (1분, 5분, 1시간 단위)
  - 로그 레벨별 카운트
  - 서비스별 카운트
  - 에러율 계산
- [X] 집계 결과를 별도 Collection에 저장
- [X] 스케줄러 구현 (cron 또는 주기적 실행)
- [X] 집계 API 엔드포인트 개발
  ```
  GET /api/stats/hourly?service=api-service&start=...&end=...
  GET /api/stats/error-rate?service=all
  ```

**완료 기준**: 집계 서비스가 주기적으로 통계를 생성하고 API로 조회 가능

**MongoDB Aggregation 예시**:
```javascript
db.logs.aggregate([
  {
    $match: {
      timestamp: { $gte: ISODate("2024-01-15T00:00:00Z") }
    }
  },
  {
    $group: {
      _id: {
        service: "$service",
        level: "$level",
        hour: { $dateToString: { format: "%Y-%m-%d-%H", date: "$timestamp" } }
      },
      count: { $sum: 1 }
    }
  }
])
```

---

### TASK-7: Grafana 대시보드 구축 (4-5시간)
- [X] Grafana 컨테이너 추가 (docker-compose)
- [X] MongoDB 데이터소스 플러그인 설치
- [X] 대시보드 패널 구성
  - 실시간 로그 유입량 그래프
  - 서비스별 로그 분포 (Pie Chart)
  - 에러 로그 타임라인
  - 최근 로그 테이블
- [X] Alert 규칙 설정 (에러율이 임계값 초과 시)
- [X] 대시보드 JSON 파일 저장 (버전 관리)

**완료 기준**: Grafana에서 실시간 로그 통계를 시각화 가능

---

### TASK-8: 성능 최적화 및 테스트 (3-4시간)
- [X] MongoDB 인덱스 최적화
  ```javascript
  db.logs.createIndex({ timestamp: -1, service: 1 })
  db.logs.createIndex({ level: 1, timestamp: -1 })
  ```
- [X] Kafka 파티션 설정 최적화
- [X] Consumer 병렬 처리 확인
- [X] 부하 테스트
  - 목표: 10,000 logs/second 처리
  - 도구: Apache JMeter, k6, 또는 자체 스크립트
- [X] 메모리 및 CPU 사용량 모니터링
- [X] 병목 지점 파악 및 개선

**완료 기준**: 초당 10,000개 로그를 안정적으로 처리

---

## ☸️ Phase 3: Kubernetes 배포 (Week 3)

### TASK-9: Kubernetes 매니페스트 작성 (5-6시간)
- [X] Minikube 또는 Kind 클러스터 설정
- [X] Namespace 생성: `log-monitoring`
- [X] ConfigMap 작성 (각 서비스 설정)
- [X] Secret 작성 (MongoDB 인증 정보)
- [X] Kafka Deployment & Service
  - StatefulSet 사용 (데이터 영속성)
  - Headless Service 설정
- [X] MongoDB Deployment & Service
  - StatefulSet + PersistentVolumeClaim
- [X] Producer Deployment
  - Replicas: 3
- [X] Consumer Deployment
  - Replicas: 3
- [X] Aggregator Deployment
- [X] Grafana Deployment & Service (LoadBalancer 또는 NodePort)
- [X] Prometheus Deployment & Service (진행 중)

**완료 기준**: 모든 서비스가 K8s 클러스터에 배포되고 정상 작동

**테스트 방법**:
```bash
kubectl get pods -n log-monitoring
kubectl logs -f <producer-pod> -n log-monitoring
kubectl port-forward svc/grafana 3000:3000 -n log-monitoring
```

---

### TASK-10: Horizontal Pod Autoscaler 설정 (2-3시간)
- [X] Metrics Server 설치
- [X] HPA 리소스 정의
  ```yaml
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: log-consumer-hpa
  spec:
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: log-consumer
    minReplicas: 2
    maxReplicas: 10
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
  ```
- [X] 부하 테스트로 Auto-scaling 확인
- [X] 스케일링 동작 모니터링

**완료 기준**: CPU 사용률에 따라 Pod가 자동으로 증가/감소

---

### TASK-11: Health Check 및 Rolling Update (2-3시간)
- [ ] Liveness Probe 추가 (각 서비스)
- [ ] Readiness Probe 추가
- [ ] Rolling Update 전략 설정
  ```yaml
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  ```
- [ ] 무중단 배포 테스트
- [ ] Rollback 시나리오 테스트

**완료 기준**: 서비스 중단 없이 새 버전 배포 가능

---

## ⛓️ Phase 4: CI/CD 파이프라인 (Week 4)

### TASK-12: GitHub Actions로 자동 빌드/테스트 (3-4시간)
- [ ] GitHub Actions Workflow 작성 `ci.yml`
- [ ] 서비스별 유닛 테스트 자동화
- [ ] Docker 이미지 빌드 및 테스트
- [ ] Lint 검사 (Code Style)
- [ ] Build 캐싱 설정 (속도 최적화)

**완료 기준**: PR 생성 시 또는 Main 브랜치 푸시 시 테스트와 빌드가 자동으로 실행됨

---

### TASK-13: Kubernetes 자동 배포 (3-4시간)
- [ ] Docker Hub 또는 GHCR(GitHub Container Registry) 계정 설정
- [ ] GitHub Secrets 설정 (DOCKER_USERNAME, DOCKER_PASSWORD, KUBE_CONFIG)
- [ ] CD Workflow 작성 `cd.yml`
  - 이미지 태그 버저닝 (Git Hash 활용)
  - Docker 이미지 Push
  - `kubectl` 또는 `kustomize`를 이용한 배포 이미지 태그 업데이트
- [ ] 배포 상태 확인 단계 추가 (`kubectl rollout status`)

**완료 기준**: 코드가 Main 브랜치에 병합되면 자동으로 클러스터에 배포됨

---

### TASK-14: 배포 전략 및 알림 (2-3시간)
- [ ] 배포 결과 알림 연동 (Slack 또는 Discord Webhook)
- [ ] 배포 실패 시 자동 롤백 설정
- [ ] 환경 분리 (Staging / Production) 전략 수립 (선택사항)

**완료 기준**: 배포 성공/실패 여부를 메신저로 수신 가능

---

## ☁️ Phase 5: GCP 배포 (Week 4-5)

### TASK-15: GCP 프로젝트 설정 (1-2시간)
- [ ] Google Cloud Platform 계정 및 프로젝트 생성
- [ ] 필요한 API 활성화 (GKE, Artifact Registry, Cloud Build 등)
- [ ] `gcloud` CLI 로컬 인증 설정
- [ ] 서비스 계정(Service Account) 생성 및 권한 부여

**완료 기준**: 로컬에서 GCP 프로젝트에 접근 가능

---

### TASK-16: GKE 클러스터 생성 (3-4시간)
- [ ] GKE Standard 또는 Autopilot 클러스터 생성
- [ ] 노드 풀 설정 (E2-medium 등 비용 효율적인 인스턴스 선택)
- [ ] `kubectl` 컨텍스트 연결
- [ ] Namespace 및 기본 설정 마이그레이션

**완료 기준**: GKE 클러스터가 정상 동작하고 `kubectl`로 제어 가능

---

### TASK-17: 영구 스토리지 설정 (2-3시간)
- [ ] GCP Persistent Disk용 StorageClass 확인
- [ ] MongoDB PVC를 GCP 디스크와 연동
- [ ] 데이터 마이그레이션 (로컬/Minikube -> GKE)

**완료 기준**: Pod 재시작 후에도 데이터가 유지되는지 확인

---

### TASK-18: 네트워크 및 보안 (4-5시간)
- [ ] 정적 IP (Static IP) 예약
- [ ] Ingress Controller 설정 (Nginx Ingress 또는 GKE Ingress)
- [ ] 도메인 연결 (nip.io 또는 실제 도메인 사용)
- [ ] LoadBalancer 서비스 노출
- [ ] 방화벽 규칙 검토 및 설정

**완료 기준**: 외부 퍼블릭 IP/도메인을 통해 서비스 접근 가능

---

### TASK-19: GCP Monitoring/Logging 통합 (3-4시간)
- [ ] Cloud Operations (Stackdriver) 활성화
- [ ] Prometheus/Grafana 데이터를 영구 스토리지에 저장
- [ ] GKE 메트릭 대시보드 확인

**완료 기준**: GCP 콘솔에서도 클러스터 상태 확인 가능

---

### TASK-20: 비용 최적화 전략 (2시간)
- [ ] Preemptible(Spot) VM 활용 검토
- [ ] 미사용 리소스 정리 스크립트
- [ ] 예산 알림(Budget Alert) 설정

**완료 기준**: 불필요한 과금 방지 조치 완료

---

## 📚 Phase 6: 문서화 및 마무리 (Week 5)

### TASK-21: 아키텍처 다이어그램 작성 (2시간)
- [ ] 시스템 전체 아키텍처 다이어그램 (GCP 포함)
- [ ] CI/CD 파이프라인 흐름도
- [ ] Kubernetes 리소스 구조도
- [ ] 도구: draw.io, Lucidchart, 또는 PlantUML

**완료 기준**: 누구나 이해할 수 있는 시각화 자료 완성

---

### TASK-22: README 작성 (3-4시간)
- [ ] 프로젝트 소개 및 데모 영상/스크린샷
- [ ] 기술 스택 및 선택 이유
- [ ] 클라우드 아키텍처 설명
- [ ] 로컬 및 GKE 배포 가이드
- [ ] API 문서
- [ ] 트러블슈팅 가이드

**완료 기준**: 외부 개발자가 문서를 보고 프로젝트를 이해하고 실행 가능

---

## 🎁 선택적 개선 사항 (시간 여유 시)

### TASK-23: 추가 기능 구현 (선택)
- [ ] Elasticsearch 연동 (전문 검색)
- [ ] Redis 캐싱 레이어 추가
- [ ] 로그 retention 정책 구현 (오래된 로그 자동 삭제)
- [ ] API 인증 추가 (JWT)
- [ ] Helm Chart 작성

---

## 📊 진행 상황 체크리스트

### Week 1 목표
- [x] 로컬 개발 환경 구축
- [x] Producer, Consumer 서비스 개발
- [x] 기본 로그 수집 파이프라인 완성

### Week 2 목표
- [x] 집계 서비스 및 API 개발
- [x] Grafana 대시보드 구축
- [x] 성능 테스트 및 최적화

### Week 3 목표
- [x] Kubernetes 배포
- [x] Auto-scaling 설정
- [ ] 헬스 체크 및 무중단 배포 적용

### Week 4-5 목표
- [ ] CI/CD 파이프라인 구축
- [ ] GCP GKE 클러스터 배포
- [ ] 외부 접근 설정 (Ingress)
- [ ] 최종 문서화

---

## 🚨 트러블슈팅 예상 포인트 (업데이트)

1. **GitHub Actions 권한 문제**
   - Secrets 설정 누락 확인, GITHUB_TOKEN 권한 확인

2. **GKE 스토리지 마운트 실패**
   - StorageClass 이름 불일치, 영역(Zone) 불일치 확인

3. **Ingress 접속 불가**
   - Health Check 실패, 방화벽 포트 오픈 여부 확인

4. **과금 폭탄**
   - 사용하지 않는 클러스터는 반드시 삭제 확인

---

## 🎯 최종 성공 지표

- **자동화**: 코드 푸시부터 배포까지 원클릭 자동화
- **클라우드 운영**: 실제 운영 환경(GCP)에서 안정적인 서비스 제공
- **확장성**: 부하 발생 시 노드/파드 자동 스케일링
- **가시성**: 전체 시스템의 상태를 한눈에 파악 가능한 대시보드